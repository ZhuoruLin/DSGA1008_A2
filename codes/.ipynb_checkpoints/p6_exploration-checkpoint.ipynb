{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import neccesary packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import model\n",
    "import data\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/zhuorulin/Documents/DataScience/datasets/glove.6B/glove.6B.50d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6e0de6334b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#Using 50 dimension embeddding for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_home\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'glove.6B.50d.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mloaded_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/zhuorulin/Documents/DataScience/datasets/glove.6B/glove.6B.50d.txt'"
     ]
    }
   ],
   "source": [
    "# Using pretrained GloVe 6 Billion Tokens embeddings\n",
    "# To download, please go to: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# To download more complex version: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "#Specify GloVe embeddings files directory\n",
    "glove_home = '/Users/zhuorulin/Documents/DataScience/datasets/glove.6B/'\n",
    "\n",
    "#Import only a portion of words for testing\n",
    "words_to_load = 50000\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Using 50 dimension embeddding for testing\n",
    "with open(glove_home + 'glove.6B.50d.txt') as f:\n",
    "    loaded_embeddings = np.zeros((words_to_load, 50))\n",
    "    words = {}\n",
    "    ordered_words = []\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        \n",
    "        s = line.split()\n",
    "        loaded_embeddings[i, :] = np.asarray(s[1:])\n",
    "        words[s[0]] = i\n",
    "        ordered_words.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39533  , -0.0064782, -0.26112  , -0.32292  ,  0.96181  ,\n",
       "        0.11242  , -0.30927  ,  0.17085  , -0.38948  ,  0.77584  ,\n",
       "       -0.31334  ,  0.54971  , -0.4579   ,  0.05835  ,  1.0643   ,\n",
       "        0.57949  ,  0.74198  ,  0.22064  ,  0.11507  , -0.84422  ,\n",
       "       -0.43365  ,  0.52626  ,  0.067037 ,  0.16294  ,  1.1345   ,\n",
       "       -2.0336   , -1.211    ,  0.69115  ,  1.418    , -0.80188  ,\n",
       "        3.0172   ,  0.36111  , -0.38275  , -0.51099  , -0.19531  ,\n",
       "       -0.16375  , -0.024037 ,  0.32332  , -0.0070115, -0.49139  ,\n",
       "       -0.28394  ,  0.06881  , -0.11819  ,  0.47825  ,  0.16551  ,\n",
       "        0.29805  ,  0.010174 ,  0.20346  , -0.13682  ,  0.79782  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To access the word embedding of certain word use the format loaded_embedings[words['someword']]\n",
    "#Example:\n",
    "loaded_embeddings[words['something']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How to access saved model and its embedding\n",
    "(For t-SNE plotting)\n",
    "An example of trained model file outputed by main.py can be obtained by simply running \n",
    "python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8473b33f8ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./saved_models/baseline_20epcs.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# try the legacy loader first, which only works if f is a tarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlegacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTarError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36mlegacy_load\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_with_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                     \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mdevice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m         raise RuntimeError(\n\u001b[1;32m     95\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "test_model = torch.load('./saved_models/baseline_20epcs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Access embedding encoder\n",
    "embeddings = test_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0584227   0.06738488 -0.09146285  0.09027602 -0.00553663  0.06121026\n",
      "  -0.02869502  0.09575699  0.00909212 -0.0371874   0.09213921 -0.06997923\n",
      "  -0.00163003  0.00070393  0.09747472  0.0730431   0.050972   -0.09374902\n",
      "   0.09427254 -0.02971593 -0.01190037  0.09512663  0.09175614  0.06701317\n",
      "  -0.06477593  0.06747179 -0.03590024  0.09678961 -0.02077954 -0.03717487\n",
      "   0.09399399  0.05078898 -0.03373756  0.07167596 -0.01005025 -0.08891959\n",
      "   0.01151292  0.08840706  0.05733902 -0.0304296  -0.0959112   0.09701306\n",
      "  -0.0543106  -0.09391937 -0.06585642  0.00093385 -0.02688372 -0.07140672\n",
      "   0.09044622  0.0079434 ]]\n"
     ]
    }
   ],
   "source": [
    "#Access the embedding of certain index\n",
    "index = torch.autograd.Variable(torch.LongTensor([1]))\n",
    "print(embeddings(index).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings(index).data.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 6.9161e-02 -7.4805e-02  6.9472e-02  ...  -5.3911e-02 -6.7033e-02  4.6637e-02\n",
       " 5.8423e-02  6.7385e-02 -9.1463e-02  ...  -7.1407e-02  9.0446e-02  7.9434e-03\n",
       " 9.3252e-02 -6.2379e-02 -4.9981e-02  ...  -8.9035e-02  5.9305e-02  9.1563e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 2.4863e-02  1.1415e-01 -6.2715e-02  ...  -5.3927e-02 -7.8696e-02  1.4376e-01\n",
       "-1.7399e-01 -5.9539e-02  5.8550e-02  ...  -3.3759e-02 -6.9809e-02 -4.1872e-02\n",
       "-8.1804e-02  1.3174e-01 -1.2040e-01  ...   3.4032e-02 -8.4751e-02  1.1907e-01\n",
       "[torch.FloatTensor of size 10000x50]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load saved infosheets\n",
    "import pickle\n",
    "with open('info.pk','rb') as f:\n",
    "    info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings = info['embeddings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = data.Corpus('../Starter_Codes/data/penn')\n",
    "def batchify(data, bsz):\n",
    "    nbatch = data.size(0) // bsz\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    #if args.cuda:\n",
    "        #data = data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_batch_size = 10\n",
    "train_data = batchify(corpus.train, 64)\n",
    "val_data = batchify(corpus.valid, 64)\n",
    "test_data = batchify(corpus.test, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened\n",
      "1410\n",
      "5401\n",
      "5992\n"
     ]
    }
   ],
   "source": [
    "# Access word using index\n",
    "print(corpus.dictionary.idx2word[1070])\n",
    "# Access index using word\n",
    "print(corpus.dictionary.word2idx['apple'])\n",
    "print(corpus.dictionary.word2idx['orange'])\n",
    "print(corpus.dictionary.word2idx['paris'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-sne ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6361d79ea3a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindex_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mEmbeddings_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_to_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "# Using sklearn.manifold.TSNE package\n",
    "# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "index_to_plot = torch.autograd.Variable(torch.LongTensor(np.arange(0,50,1)))\n",
    "Embeddings_to_plot = embeddings(index_to_plot).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####Using preloaded embeddings\n",
    "index = np.arange(0,50,1)\n",
    "Embeddings_to_plot = embeddings[index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "TSNE_model = TSNE(n_components=2,random_state=0)\n",
    "#Transfer to 2 dimensions\n",
    "representations2D = TSNE_model.fit_transform(Embeddings_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_to_plot = corpus.dictionary.idx2word[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1169d59e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(representations2D[:,0],representations2D[:,1],marker='X',s=0.5)\n",
    "plt.\n",
    "#for word_idx,word in enumerate(words_to_plot):\n",
    "#    plt.annotate(word,representations2D[word_idx])\n",
    "#plt.xlim([-100,100])\n",
    "#plt.ylim([-100,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize embeddings with pretrained GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
