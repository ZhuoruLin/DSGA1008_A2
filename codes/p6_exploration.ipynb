{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import neccesary packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import model\n",
    "import data\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/zhuorulin/Documents/DataScience/datasets/glove.6B/glove.6B.50d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6e0de6334b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#Using 50 dimension embeddding for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_home\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'glove.6B.50d.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mloaded_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/zhuorulin/Documents/DataScience/datasets/glove.6B/glove.6B.50d.txt'"
     ]
    }
   ],
   "source": [
    "# Using pretrained GloVe 6 Billion Tokens embeddings\n",
    "# To download, please go to: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# To download more complex version: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "#Specify GloVe embeddings files directory\n",
    "glove_home = '/Users/zhuorulin/Documents/DataScience/datasets/glove.6B/'\n",
    "\n",
    "#Import only a portion of words for testing\n",
    "words_to_load = 50000\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Using 50 dimension embeddding for testing\n",
    "with open(glove_home + 'glove.6B.50d.txt') as f:\n",
    "    loaded_embeddings = np.zeros((words_to_load, 50))\n",
    "    words = {}\n",
    "    ordered_words = []\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        \n",
    "        s = line.split()\n",
    "        loaded_embeddings[i, :] = np.asarray(s[1:])\n",
    "        words[s[0]] = i\n",
    "        ordered_words.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39533  , -0.0064782, -0.26112  , -0.32292  ,  0.96181  ,\n",
       "        0.11242  , -0.30927  ,  0.17085  , -0.38948  ,  0.77584  ,\n",
       "       -0.31334  ,  0.54971  , -0.4579   ,  0.05835  ,  1.0643   ,\n",
       "        0.57949  ,  0.74198  ,  0.22064  ,  0.11507  , -0.84422  ,\n",
       "       -0.43365  ,  0.52626  ,  0.067037 ,  0.16294  ,  1.1345   ,\n",
       "       -2.0336   , -1.211    ,  0.69115  ,  1.418    , -0.80188  ,\n",
       "        3.0172   ,  0.36111  , -0.38275  , -0.51099  , -0.19531  ,\n",
       "       -0.16375  , -0.024037 ,  0.32332  , -0.0070115, -0.49139  ,\n",
       "       -0.28394  ,  0.06881  , -0.11819  ,  0.47825  ,  0.16551  ,\n",
       "        0.29805  ,  0.010174 ,  0.20346  , -0.13682  ,  0.79782  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To access the word embedding of certain word use the format loaded_embedings[words['someword']]\n",
    "#Example:\n",
    "loaded_embeddings[words['something']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How to access saved model and its embedding\n",
    "(For t-SNE plotting)\n",
    "An example of trained model file outputed by main.py can be obtained by simply running \n",
    "python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonlzr/anaconda3/lib/python3.5/site-packages/torch/serialization.py:284: SourceChangeWarning: source code of class 'model.RNNModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/simonlzr/anaconda3/lib/python3.5/site-packages/torch/serialization.py:284: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/simonlzr/anaconda3/lib/python3.5/site-packages/torch/serialization.py:284: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/simonlzr/anaconda3/lib/python3.5/site-packages/torch/serialization.py:284: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "test_model = torch.load('./saved_models/baseline_20epcs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Access embedding encoder\n",
    "embeddings = test_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05410157  0.00914382 -0.02619506 -0.03508313 -0.10940051  0.11662303\n",
      "  -0.0391235   0.14047623 -0.01419645 -0.0583433   0.15861873  0.08402319\n",
      "  -0.02805875  0.08336291  0.3064045   0.14163132 -0.05227244 -0.01660749\n",
      "  -0.00345682 -0.06356572  0.02832948  0.14776705  0.14149755  0.08763231\n",
      "  -0.01289891  0.07681017 -0.08612793 -0.021301   -0.09356862 -0.16724671\n",
      "   0.11338127  0.19931795  0.01676324  0.13795891 -0.15934202 -0.09487032\n",
      "  -0.02861047  0.05946425  0.10910583 -0.0162857  -0.15224901  0.05008053\n",
      "  -0.09350243 -0.07216047 -0.05812501  0.05326393  0.16828595  0.0536381\n",
      "   0.09615086 -0.04556962]]\n"
     ]
    }
   ],
   "source": [
    "#Access the embedding of certain index\n",
    "index = torch.autograd.Variable(torch.cuda.LongTensor([1]))\n",
    "print(embeddings(index).data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-5.2947e-02 -6.0556e-02  3.0369e-01  ...   7.4769e-02 -2.2228e-01 -3.3333e-02\n",
       " 5.4102e-02  9.1438e-03 -2.6195e-02  ...   5.3638e-02  9.6151e-02 -4.5570e-02\n",
       " 7.1613e-02 -1.1282e-01  3.3638e-02  ...   2.3517e-02  5.2494e-02  3.9618e-02\n",
       "                ...                   ⋱                   ...                \n",
       "-4.1156e-01  2.7232e-01 -3.3668e-01  ...  -2.8468e-01  7.3748e-02  1.9785e-01\n",
       "-9.2592e-02 -1.9704e-01  1.6453e-01  ...   1.8624e-01 -1.4785e-01 -3.7434e-02\n",
       " 2.3761e-02  2.9175e-01 -4.9306e-01  ...   3.1733e-01 -3.8825e-01 -4.7934e-02\n",
       "[torch.cuda.FloatTensor of size 10000x50 (GPU 0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load saved infosheets\n",
    "import pickle\n",
    "with open('info.pk','rb') as f:\n",
    "    info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings = info['embeddings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = data.Corpus('../Starter_Codes/data/penn')\n",
    "def batchify(data, bsz):\n",
    "    nbatch = data.size(0) // bsz\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    #if args.cuda:\n",
    "        #data = data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_batch_size = 10\n",
    "train_data = batchify(corpus.train, 64)\n",
    "val_data = batchify(corpus.valid, 64)\n",
    "test_data = batchify(corpus.test, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened\n",
      "1410\n",
      "5401\n",
      "5992\n"
     ]
    }
   ],
   "source": [
    "# Access word using index\n",
    "print(corpus.dictionary.idx2word[1070])\n",
    "# Access index using word\n",
    "print(corpus.dictionary.word2idx['apple'])\n",
    "print(corpus.dictionary.word2idx['orange'])\n",
    "print(corpus.dictionary.word2idx['paris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test Data loader utilitie\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data,batch_size=len(train_data),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   24    24  1082  ...    108   794   189\n",
       " 2324    48    32  ...     24   804  1800\n",
       "  938  1195    56  ...     75  1282  1661\n",
       "       ...          ⋱          ...       \n",
       " 2378    35    95  ...    734   159   108\n",
       "   26  1028  4386  ...     58  5831   597\n",
       "   24   525    24  ...    706  9678   490\n",
       "[torch.LongTensor of size 14524x64]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-sne ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6361d79ea3a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindex_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mEmbeddings_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_to_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "# Using sklearn.manifold.TSNE package\n",
    "# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "index_to_plot = torch.autograd.Variable(torch.LongTensor(np.arange(0,50,1)))\n",
    "Embeddings_to_plot = embeddings(index_to_plot).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####Using preloaded embeddings\n",
    "index = np.arange(0,50,1)\n",
    "Embeddings_to_plot = embeddings[index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "TSNE_model = TSNE(n_components=2,random_state=0)\n",
    "#Transfer to 2 dimensions\n",
    "representations2D = TSNE_model.fit_transform(Embeddings_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_to_plot = corpus.dictionary.idx2word[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1169d59e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(representations2D[:,0],representations2D[:,1],marker='X',s=0.5)\n",
    "plt.\n",
    "#for word_idx,word in enumerate(words_to_plot):\n",
    "#    plt.annotate(word,representations2D[word_idx])\n",
    "#plt.xlim([-100,100])\n",
    "#plt.ylim([-100,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic parameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.system('python main.py --cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting grid.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile grid.py\n",
    "import os\n",
    "emsizes = [100,500,1000]\n",
    "nhids = [100,500,1000]\n",
    "nlayers = [2,3]\n",
    "models = ['LSTM','GRU']\n",
    "for model in models:\n",
    "    for emsize in emsizes:\n",
    "        for nhid in nhids:\n",
    "            for nlayer in nlayers:\n",
    "                save_path = 'saved_models/%s_%s_%s_%s.pt' %(model,nlayer,emsize,nhid)\n",
    "                info_path = 'info_dict/%s_%s_%s_%s.pk' %(model,nlayer,emsize,nhid)\n",
    "                cmdLine = 'python main.py --cuda --epochs 20 --batch-size 200 --model %s --nlayers %s --emsize %s --nhid %s\\\n",
    "                --save %s --infopath %s'%(model,nlayer,emsize,nhid,save_path,info_path)\n",
    "                print(cmdLine)\n",
    "                os.system(cmdLine)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
