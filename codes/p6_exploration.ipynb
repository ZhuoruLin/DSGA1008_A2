{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import neccesary packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import model\n",
    "import data\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/zhuorulin/Documents/DataScience/datasets/glove.6B/glove.6B.50d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6e0de6334b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#Using 50 dimension embeddding for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_home\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'glove.6B.50d.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mloaded_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/zhuorulin/Documents/DataScience/datasets/glove.6B/glove.6B.50d.txt'"
     ]
    }
   ],
   "source": [
    "# Using pretrained GloVe 6 Billion Tokens embeddings\n",
    "# To download, please go to: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# To download more complex version: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "#Specify GloVe embeddings files directory\n",
    "glove_home = '/Users/zhuorulin/Documents/DataScience/datasets/glove.6B/'\n",
    "\n",
    "#Import only a portion of words for testing\n",
    "words_to_load = 50000\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Using 50 dimension embeddding for testing\n",
    "with open(glove_home + 'glove.6B.50d.txt') as f:\n",
    "    loaded_embeddings = np.zeros((words_to_load, 50))\n",
    "    words = {}\n",
    "    ordered_words = []\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        \n",
    "        s = line.split()\n",
    "        loaded_embeddings[i, :] = np.asarray(s[1:])\n",
    "        words[s[0]] = i\n",
    "        ordered_words.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39533  , -0.0064782, -0.26112  , -0.32292  ,  0.96181  ,\n",
       "        0.11242  , -0.30927  ,  0.17085  , -0.38948  ,  0.77584  ,\n",
       "       -0.31334  ,  0.54971  , -0.4579   ,  0.05835  ,  1.0643   ,\n",
       "        0.57949  ,  0.74198  ,  0.22064  ,  0.11507  , -0.84422  ,\n",
       "       -0.43365  ,  0.52626  ,  0.067037 ,  0.16294  ,  1.1345   ,\n",
       "       -2.0336   , -1.211    ,  0.69115  ,  1.418    , -0.80188  ,\n",
       "        3.0172   ,  0.36111  , -0.38275  , -0.51099  , -0.19531  ,\n",
       "       -0.16375  , -0.024037 ,  0.32332  , -0.0070115, -0.49139  ,\n",
       "       -0.28394  ,  0.06881  , -0.11819  ,  0.47825  ,  0.16551  ,\n",
       "        0.29805  ,  0.010174 ,  0.20346  , -0.13682  ,  0.79782  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To access the word embedding of certain word use the format loaded_embedings[words['someword']]\n",
    "#Example:\n",
    "loaded_embeddings[words['something']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How to access saved model and its embedding\n",
    "(For t-SNE plotting)\n",
    "An example of trained model file outputed by main.py can be obtained by simply running \n",
    "python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8473b33f8ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./saved_models/baseline_20epcs.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# try the legacy loader first, which only works if f is a tarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlegacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTarError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36mlegacy_load\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_with_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                     \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mdevice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m         raise RuntimeError(\n\u001b[1;32m     95\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhuorulin/anaconda/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "test_model = torch.load('./saved_models/baseline_20epcs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Access embedding encoder\n",
    "embeddings = test_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0584227   0.06738488 -0.09146285  0.09027602 -0.00553663  0.06121026\n",
      "  -0.02869502  0.09575699  0.00909212 -0.0371874   0.09213921 -0.06997923\n",
      "  -0.00163003  0.00070393  0.09747472  0.0730431   0.050972   -0.09374902\n",
      "   0.09427254 -0.02971593 -0.01190037  0.09512663  0.09175614  0.06701317\n",
      "  -0.06477593  0.06747179 -0.03590024  0.09678961 -0.02077954 -0.03717487\n",
      "   0.09399399  0.05078898 -0.03373756  0.07167596 -0.01005025 -0.08891959\n",
      "   0.01151292  0.08840706  0.05733902 -0.0304296  -0.0959112   0.09701306\n",
      "  -0.0543106  -0.09391937 -0.06585642  0.00093385 -0.02688372 -0.07140672\n",
      "   0.09044622  0.0079434 ]]\n"
     ]
    }
   ],
   "source": [
    "#Access the embedding of certain index\n",
    "index = torch.autograd.Variable(torch.LongTensor([1]))\n",
    "print(embeddings(index).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings(index).data.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 6.9161e-02 -7.4805e-02  6.9472e-02  ...  -5.3911e-02 -6.7033e-02  4.6637e-02\n",
       " 5.8423e-02  6.7385e-02 -9.1463e-02  ...  -7.1407e-02  9.0446e-02  7.9434e-03\n",
       " 9.3252e-02 -6.2379e-02 -4.9981e-02  ...  -8.9035e-02  5.9305e-02  9.1563e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 2.4863e-02  1.1415e-01 -6.2715e-02  ...  -5.3927e-02 -7.8696e-02  1.4376e-01\n",
       "-1.7399e-01 -5.9539e-02  5.8550e-02  ...  -3.3759e-02 -6.9809e-02 -4.1872e-02\n",
       "-8.1804e-02  1.3174e-01 -1.2040e-01  ...   3.4032e-02 -8.4751e-02  1.1907e-01\n",
       "[torch.FloatTensor of size 10000x50]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load saved infosheets\n",
    "import pickle\n",
    "with open('info.pk','rb') as f:\n",
    "    info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings = info['embeddings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = data.Corpus('../Starter_Codes/data/penn')\n",
    "def batchify(data, bsz):\n",
    "    nbatch = data.size(0) // bsz\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    #if args.cuda:\n",
    "        #data = data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_batch_size = 10\n",
    "train_data = batchify(corpus.train, 64)\n",
    "val_data = batchify(corpus.valid, 64)\n",
    "test_data = batchify(corpus.test, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access word using index\n",
    "print(corpus.dictionary.idx2word[1070])\n",
    "# Access index using word\n",
    "corpus.dictionary.word2idx['claims']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-sne ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6361d79ea3a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindex_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mEmbeddings_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_to_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "# Using sklearn.manifold.TSNE package\n",
    "# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "index_to_plot = torch.autograd.Variable(torch.LongTensor(np.arange(0,50,1)))\n",
    "Embeddings_to_plot = embeddings(index_to_plot).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####Using preloaded embeddings\n",
    "index = np.arange(0,50,1)\n",
    "Embeddings_to_plot = embeddings[index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "TSNE_model = TSNE(n_components=2,random_state=0)\n",
    "#Transfer to 2 dimensions\n",
    "representations2D = TSNE_model.fit_transform(Embeddings_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_to_plot = corpus.dictionary.idx2word[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d977f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(representations2D[:,0],representations2D[:,1])\n",
    "#for word_idx,word in enumerate(words_to_plot):\n",
    "#    plt.annotate(word,representations2D[word_idx])\n",
    "#plt.xlim([-100,100])\n",
    "#plt.ylim([-100,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize embeddings with pretrained GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
