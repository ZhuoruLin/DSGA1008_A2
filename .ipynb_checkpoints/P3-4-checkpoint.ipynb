{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Variants of Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) List three different kinds of pooling, and their corresponding module implemented in PyTorch.\n",
    "The three types of pooling are:\n",
    "- Max pooling: implemented in torch.nn.MaxPool1d/MaxPool2d/MaxPool3d\n",
    "- Average pooling : implemented in torch.nn.AvgPool1d/AvgPool2d/AvgPool3d\n",
    "- Power-average pooling: implemented in torch.nn.LPPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Write down the mathematical forms of these three pooling modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let C be the number of channels of a pixel, H and W be the height and width of the input image; The kernel size for pooling is (kH,kW); \n",
    "\n",
    "The 2d maximun pooling would return:\n",
    "$$\n",
    "Out(C_j,h,w) = Max_{m=0}^{kH-1} Max_{n=0}^{kW-1} In(C_j,stride[0]*h+m,stride[1]*w+n)\n",
    "$$\n",
    "\n",
    "The 2d average pooling would return:\n",
    "$$\n",
    "Out(C_j,h,w) = \\frac{1}{kH*kW}\\sum \\limits_{m=0}^{kH-1} \\sum \\limits_{n=0}^{kW-1} In(C_j,stride[0]*h+m,stride[1]*w+n)\n",
    "$$\n",
    "\n",
    "The 2d Power average pooling would return:\n",
    "\n",
    "$$\n",
    "Out(C_j,h,w) = (\\sum \\limits_{m=0}^{kH-1} \\sum \\limits_{n=0}^{kW-1} (In(C_j,stride[0]*h+m,stride[1]*w+n))^p)^{\\frac{1}{p}}\n",
    "$$\n",
    "\n",
    "Note that when $p = 1$ and $p = \\infty$, power average pooling is equivalent to average pooling and maximun pooling respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Pick one of the pooling listed and describe the reason for incorporating it into a deep\n",
    "learning system.\n",
    "For image classification we used max-pooling becauses it was experimentally shown to capture more translated invariant features.\n",
    "\n",
    "References\n",
    "\n",
    "http://yann.lecun.com/exdb/publis/pdf/boureau-icml-10.pdf\n",
    "\n",
    "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7172506\n",
    "\n",
    "http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 t-SNE\n",
    "### 1) What is the crowding problem and how does t-SNE alleviate it? Give details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crowding problem occurs when trying to map moderately distant points in high dimension space to 2 dimensions. The area of a sphere in a 2 dimensional space is smaller than the sphere with same radius in a high dimensional space, resulting in insufficient area to hold the same number of data points. In order to more accurately represent pairwise distances relations, the 2-dimensional map tends to assign higher distances to moderate distant points. \n",
    "\n",
    "The cost function of SNE is inversely related to the distance of the lower dimensional map between two points. As a result, the stochastic gradient descent process has a tendency to pulls clusters of data points towards their shared center. This phenomena is similar to the spring force and many other attraction forces in physics as mensioned in Maaten and Hinton's paper. Such attraction forces generally prevent cluster from being seperated.\n",
    "\n",
    "t-SNE uses a t-distribution instead of gaussian distribution for $q_{j|i}$. With a stronger tail, t-distribution assigns a larger $q_{j|i}$ to the same pair of data points when the distance is large. Therefore the mapped data points in 2-dimensional space can be sufficiently represented by larger distances, allowing cluster gaps to form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Please derive $\\frac{\\partial C}{\\partial y_i}$ in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following steps are also shown in Maaten and Hinton's Paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of C is given by:\n",
    "$$\n",
    "C = \\sum \\limits_i \\sum \\limits_j p_{ij} log \\frac{p_{ij}}{q_{ij}} = \\sum \\limits_i \\sum \\limits_j p_{ij}log(p_{ij})-\\sum \\limits_i \\sum \\limits_j p_{ij} log(q_{ij})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "$$\n",
    "p_{ij} = \\frac{exp(-\\lvert \\lvert x_i-x_j\\rvert \\rvert^2 /2 \\sigma^2)}{\\sum_{k \\neq l}exp(-\\lvert \\lvert x_k-x_l\\rvert \\rvert^2 /2 \\sigma^2)}\n",
    "\\\\\n",
    "q_{ij} = \\frac{(1+\\lvert \\lvert y_i-y_j \\rvert \\rvert^2)^{-1}}{\\sum_{k \\neq l}(1+\\lvert \\lvert y_i-y_j \\rvert \\rvert^2)^{-1}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define:\n",
    "$$\n",
    "d_{ij} = \\lvert \\lvert y_i-y_j \\rvert \\rvert \\\\\n",
    "Z = \\sum_{k \\neq l}(1+d_{kl}^2)^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must have:\n",
    "$$\n",
    "(1+d_{ij}^2)^{-1} = q_{ij}Z\n",
    "$$\n",
    "\n",
    "\n",
    "Notice that in our definition of $C$, only $q_{ij}(d_{ij})$ and $q_{ji}(d_{ji})$ are functions of $y_i$. With symetry definition of SNE we have $d_{ij}=d_{ji}$. Therefore:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial y_i} = 2 \\sum_j \\frac{\\partial C}{\\partial d_{ij}}(y_i-y_j)\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial C}{\\partial d_{ij}}$ is computed by:\n",
    "\n",
    "\\begin{split}\n",
    "\\frac{\\partial C}{\\partial d_{ij}} &= -p_{ij}\\frac{\\partial log(q_{ij}Z)}{d_{ij}}+\\sum_{k\\neq l}p_{kl}\\frac{\\partial log(Z)}{d_{ij}}\\\\\n",
    "&=2\\frac{p_{ij}}{q_{ij}Z}(1+d_{ij}^2)^{-2}-2\\sum_{k\\neq l}\\frac{p_{kl}}{Z}(1+d_{ij}^2)^{-2}\n",
    "\\end{split}\n",
    "\n",
    "Since $p_{kl}$ is a well-defined probability distribution, $\\sum_{k\\neq l}p_{kl}$ is 1.  Also by definition of Z we have $(1+d_{ij}^2)^{-1} = q_{ij}Z$ and $Z=\\frac{(1+d_{ij}^2)^{-1}}{q_{ij}}$. Therefore:\n",
    "\n",
    "\\begin{split}\n",
    "\\frac{\\partial C}{\\partial d_{ij}} &=2p_{ij}(1+d_{ij}^2)^{-1}-2q_{ij}(1+d_{ij}^2)^{-1}\n",
    "&=2(p_{ij}-q_{ij})(1+d_{ij}^2)^{-1}\n",
    "\\end{split}\n",
    "\n",
    "Plug in the definition of $\\frac{\\partial C}{\\partial d_{ij}}$ back, we get:\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial y_i} = 4(p_{ij}-q_{ij})(1+\\lvert \\lvert y_i-y_j \\rvert \\rvert ^2)^{-1}(y_i-y_j)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
